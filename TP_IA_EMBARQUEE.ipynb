{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLQS0KLMycmb"
      },
      "source": [
        "## **PRACTICAL SESSION 1** — Deep Learning for predictive maintenance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mjNAfgj4K1_"
      },
      "source": [
        "The dataset used is the **AI4I 2020** Predictive Maintenance Dataset, which contains 10,000 instances of industrial sensor data. Each instance represents the operating condition of a machine and is associated with a label indicating whether a failure has occurred and, if so, what type of failure it is.\n",
        "\n",
        "The 5 possible labels are:\n",
        "\n",
        "\n",
        "\n",
        "*   **TWF**: Tool Wear Failure\n",
        "*   **HDF**: Heat Dissipation Failure\n",
        "*   **PWF**: Power Failure\n",
        "*   **OSF**: Overstrain Failure\n",
        "*   **RNF**: Random Failure\n",
        "\n",
        "\n",
        "The data is available on eCAMPUS as CSV file called: \"ai4i2020.csv\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_LBMVsgRI9W"
      },
      "source": [
        "## **PRACTICAL SESSION Goal** — Ceate a deep leanring model allowing to realize a predictive maintenance mission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt7L0p4MbIIw"
      },
      "source": [
        "## **1 - Analysis of the dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JFIZ6mtRapt"
      },
      "source": [
        "All libraries used ***SHOULD BE PLACED*** in the code cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
            "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install matplotlib\n",
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQp7FGSb5Vlv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFRcS74MDeSf"
      },
      "source": [
        "**QUESTION:** Load dataset and display some lines of the csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l044FZ_5-fN"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('ai4i2020.csv')\n",
        "\n",
        "# Display the first few lines of the dataset\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joQOXoqaD8JA"
      },
      "source": [
        "**QUESTION:** Display the distribution of machine failures and non-failures with a bar graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3Q1l9JoMs7m"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of machine failures and non-failures\n",
        "failure_counts = df['Machine failure'].value_counts()\n",
        "\n",
        "# Plot the bar graph\n",
        "failure_counts.plot(kind='bar', color=['blue', 'orange'])\n",
        "plt.title('Distribution of Machine Failures and Non-Failures')\n",
        "plt.xlabel('Machine Failure')\n",
        "plt.ylabel('COUNT')\n",
        "plt.xticks(ticks=[0, 1], labels=['Non-Failure', 'Failure'], rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCNIqXVyEkrR"
      },
      "source": [
        "**ANALYSIS QUESTION:** What do you observe?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BMGtlIWE-C0"
      },
      "source": [
        "\"Write here your response\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huU5I4x8SzlN"
      },
      "source": [
        "**ANALYSIS QUESTION:** What will be the consequence of this phenomenon on the model's learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHmYROP0TLIS"
      },
      "source": [
        "\"Write here your response\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s-mzCCsSasl"
      },
      "source": [
        "**QUESTION:** Create a bar chart showing the distribution of different failure types (TWF, HDF, PWF, OSF, RNF). Display the exact values above each bar in the chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQyJCfamMdJN"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each failure type\n",
        "failure_types = df[['TWF', 'HDF', 'PWF', 'OSF', 'RNF']].sum()\n",
        "\n",
        "# Plot the bar chart\n",
        "ax = failure_types.plot(kind='bar', color=['blue', 'orange', 'green', 'red', 'purple'])\n",
        "plt.title('Distribution of Different Failure Types')\n",
        "plt.xlabel('Failure Type')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Display the exact values above each bar\n",
        "for i in ax.containers:\n",
        "    ax.bar_label(i)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXyHa73yU8g_"
      },
      "source": [
        "**ANALYSIS QUESTION:** What do you observe?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRDFE_dsVBBU"
      },
      "source": [
        "\"Write here your response\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvaO2bEIMxLd"
      },
      "source": [
        "**QUESTION:** Create a bar chart showing the distribution of failure types (TWF, HDF, PWF, OSF, RNF) among machines that experienced a failure (Machine failure == 1). Additionally, add a \"No Specific Failure\" category to count cases where a machine failed but no specific failure type was recorded. Display the exact values above each bar in the chart.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e97htGyyMsle"
      },
      "outputs": [],
      "source": [
        "# Filter the dataframe for machines that experienced a failure\n",
        "failure_df = df[df['Machine failure'] == 1]\n",
        "\n",
        "# Count the occurrences of each failure type\n",
        "failure_types = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
        "failure_counts = failure_df[failure_types].sum()\n",
        "\n",
        "# Add a \"No Specific Failure\" category\n",
        "no_specific_failure_count = (failure_df[failure_types].sum(axis=1) == 0).sum()\n",
        "failure_counts['No Specific Failure'] = no_specific_failure_count\n",
        "\n",
        "# Plot the bar graph\n",
        "ax = failure_counts.plot(kind='bar', color=['blue', 'orange', 'green', 'red', 'purple', 'gray'])\n",
        "plt.title('Distribution of Failure Types Among Machines That Experienced a Failure')\n",
        "plt.xlabel('Failure Type')\n",
        "plt.ylabel('COUNT')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the exact values above each bar\n",
        "for p in ax.patches:\n",
        "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6_3vAQCOUGb"
      },
      "source": [
        "**ANALYSIS QUESTION:** What do you obsrve comapred to the previous question ? What can you conclude?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-6t7nqlOjMo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muXeS0eVVW6H"
      },
      "source": [
        "**QUESTION:** Display the names of the different columns in the dataset with their respective data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa9Tptu7nPMp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cezua1bMVTCM"
      },
      "source": [
        "**ANALYSIS QUESTION:** To train the model, what will be the inputs and outputs (What are the names of the columns that you will use?)? Justify your response.\n",
        "Remember, you want to predict if the machine will fail, and if so, what kind of failure. You need to yse previous results to jsurtify your response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gy8oDgxbjol"
      },
      "source": [
        "\"Write your response here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFXLkBzTiafx"
      },
      "source": [
        "## **2- Train model Without balancing the dataset**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plBeUOCKvVNU"
      },
      "source": [
        "In this section, you must build and train a model without rebalancing the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj7CMqdVbxg2"
      },
      "source": [
        "**QUESTION:** Create X_train, Y_train, X_test, and Y_test. How many elements are present in X_train, Y_train, X_test, and Y_test? (Print the values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdght-L8wQQQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'Machine failure' is the target variable\n",
        "X = df.drop(columns=['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'])\n",
        "Y = df[['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the number of elements in each set\n",
        "print(f'Number of elements in X_train: {len(X_train)}')\n",
        "print(f'Number of elements in Y_train: {len(Y_train)}')\n",
        "print(f'Number of elements in X_test: {len(X_test)}')\n",
        "print(f'Number of elements in Y_test: {len(Y_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqBuZsqKdQ7u"
      },
      "source": [
        "**QUESTION** Code below the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F35j0VRDdNLc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'Machine failure' is the target variable\n",
        "X = df.drop(columns=['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'])\n",
        "Y = df[['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the number of elements in each set\n",
        "print(f'Number of elements in X_train: {len(X_train)}')\n",
        "print(f'Number of elements in Y_train: {len(Y_train)}')\n",
        "print(f'Number of elements in X_test: {len(X_test)}')\n",
        "print(f'Number of elements in Y_test: {len(Y_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIONoP2Jdg8Q"
      },
      "source": [
        "**QUESTION** Code below the algorithms allowing to train model\n",
        "\n",
        "**WARNING!** You need to plot the training and test accuracy and loss to check if our model is overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ2bYxZydhW2"
      },
      "outputs": [],
      "source": [
        "from tf.keras.models import Sequential\n",
        "from tf.keras.layers import Dense\n",
        "from tf.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, Y_train['Machine failure'], epochs=50, validation_data=(X_test_scaled, Y_test['Machine failure']))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvmyHnqYpbf-"
      },
      "source": [
        "**QUESTION** Plot the confusion matrix and the classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUXSeJ1ZpsSP"
      },
      "source": [
        "**Tips:**\n",
        "\n",
        "*   classification report link\n",
        "\n",
        "> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "\n",
        "*   Matrix confusion\n",
        "\n",
        "> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4q5wvHNnAdu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImGsmryGkKhj"
      },
      "source": [
        "**ANALYSIS QUESTION** What do you observe? What can you conclude?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1f5OneQknZy"
      },
      "source": [
        "\"Write your response here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYUyUAN5ji0x"
      },
      "source": [
        "## **3- Train model With balancing the dataset**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQWut50JhKdD"
      },
      "source": [
        " Methods for rebalancing a dataset:\n",
        "\n",
        "\n",
        "*   Use oversampling techniques (e.g., SMOTE) to generate synthetic data for minority classes\n",
        "\n",
        "\n",
        "> https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
        "\n",
        "\n",
        "\n",
        "*   Apply undersampling techniques (e.g., random undersampling, Tomek Links, Edited Nearest Neighbors) to reduce the majority class size\n",
        "\n",
        "\n",
        "\n",
        "> https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n",
        "\n",
        "\n",
        "\n",
        "*   Use class weighting during model training to penalize errors on minority classes\n",
        "\n",
        "\n",
        "\n",
        "> https://www.tensorflow.org/tutorials/structured_data/imbalanced_data?hl=fr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--pWJzaUnXdY"
      },
      "source": [
        "**QUESTION:** Create X_train, Y_train, X_test, and Y_test. How many elements are present in X_train, Y_train, X_test, and Y_test? (Print the values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLW74cwbdr1U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YcZXIadnbcm"
      },
      "source": [
        "**ANALYSIS QUESTION:** Explain the choices you made to balance the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rku3pnWxnxhI"
      },
      "source": [
        "\"Write your response here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVryPCQFn4Dd"
      },
      "source": [
        "**QUESTION:** Code below the model architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5BGfI7TpVDD"
      },
      "source": [
        "**TIP:** It could be interesting to keep it the same as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0UbMHN6OC51"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBZyS7DdofFq"
      },
      "source": [
        "**QUESTION** Code below the algorithms allowing to train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my6Ck5JbMDOG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ftkfv5oqp0"
      },
      "source": [
        "**QUESTION** Plot the confusion matrix and the classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRmkOI_co5d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn5BBAI3pHXf"
      },
      "source": [
        "**ANALYSIS QUESTION** What do you observe? What can you conclude?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIf8rfU9pIGd"
      },
      "source": [
        "\"Write your response here\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
